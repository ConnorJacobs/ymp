from ymp.util import glob_wildcards
from ymp.config import icfg

rule megahit_partial_coassembly:
    """
    Specialized megahit assembly rule for co-assembly by column value

    use with reads.by_COLUMN.mhc/complete as target

    Same as general megahit rule, but does co-assemblies on groups in the
    data (e.g. by subject)
    """
    message:
        "Co-Assembling {wildcards.target} with megahit"
    input:
        r1="{dir}/{: sources :}.{: pairnames[0] :}.fq.gz",
        r2="{dir}/{: sources :}.{: pairnames[1] :}.fq.gz"
    output:
        fasta = "{dir}{by}.mhc/{target}.contigs.fasta.gz",
        fastg = "{dir}{by}.mhc/{target}.contigs.fastg.gz"
    log:
        "{dir}{by}.mhc/{target}.log.gz"
    params:
        workdir="{dir}{by}.mhc/{target}/",
    threads:
        16
# FIXME: work around need for run: using param
# so that conda will work
#    conda:
#        srcdir("megahit.yml")
    run:
        if isinstance(input.r1, str):
            input.r1 = [input.r1]
            input.r2 = [input.r2]
            
        csr1=",".join(input.r1)
        csr2=",".join(input.r2)

        shell("""
    # delete workdir if no opts.txt was recorded (never started really)
    [ -e {params.workdir}/opts.txt ] || rm -rf {params.workdir}

    megahit -1 {csr1} -2 {csr2} \
      --presets meta-sensitive \
      --num-cpu-threads {threads} \
      --out-dir {params.workdir} \
      --tmp-dir /scratch/$HOME/tmp \

    # quit if not finished
    [ -e {params.workdir}/done ] || exit 1

    # output zipped contigs
    pigz -p {threads} -9 -c {params.workdir}/final.contigs.fa > {output.fasta}

    # output the zipped log
    cat {params.workdir}/{{opts.txt,log}} |\
    pigz -p {threads} -9 -c > {log}

    # determine largest K used
    MAXK=`tac {params.workdir}/log | sed -nr 's/^---.*k = ([0-9]{{2,3}}) ---/\\1/p;' | head -n1`

    # output the zipped fastg
    megahit_toolkit contig2fastg $MAXK \
    {params.workdir}/intermediate_contigs/k${{MAXK}}.contigs.fa |\
    pigz -p {threads} -9 -c > {output.fastg}

    # remove intermediate contigs
    #rm -rf {params.workdir}
    """)




    
    
rule bbmap_gene_cat:
    message:
        "BBMap mapping to {wildcards.ref} - {wildcards.sample}"
    output:
        stats="{dir}.mh.blast.map/{ref}__{sample}.stats"
    input:
        ref="{dir}.mh.blast/{ref}.fasta.gz",
        pairs="{dir}/{sample}.{: pairnames :}.fq.gz"
    log:
        "{dir}.mh.blast.map/{ref}__{sample}.log"
    threads:
        8
    conda:
        srcdir("bbmap.yml")
    shell: """
    bbmap.sh nodisk pigz unpigz jni machineout \
      threads={threads} \
      ref={input.ref} \
      in={input.pairs[0]} in2={input.pairs[1]} \
      minid=0.99 \
      statsfile={output.stats} > {log} 2>&1
    """
             
rule gene_presence_table:
    message:
        "IMP creating RMPM table {output}"
    output:
        stats="{dir}.mh.blast.map/{ref}.csv"
    input:
        "{dir}.mh.blast.map/{ref}__{: runs :}.stats"
    params:
        re="{dir}.mh.blast.map/{ref}__(.+).stats"
    run:
        import csv, fileinput
        sample_re = re.compile(params.re)
        fields = ['sample', 'reads', 'mapped', 'rmpm']
        with open(output[0], "w") as outf, fileinput.input(input) as f:
            out = csv.DictWriter(outf, fields)
            out.writeheader()
            for line in f:
                if f.isfirstline():
                    data={}
                    sample = sample_re.match(f.filename()).group(1)
                    
                if not "=" in line: continue
                key, val = line.strip().split('=')
                try:
                    val = int(val)
                except Exception as e:
                    continue
                
                data[key] = val

                if key == "R2_Mapped_Reads":
                    row = {
                        'mapped': data['R1_Mapped_Reads'] + data['R2_Mapped_Reads'],
                        'reads':data['Reads_Used'],
                        'sample':sample
                    }
                    row['rmpm'] = row['mapped'] / row['reads'] * 1000000
                    out.writerow(row)

rule gene_presence_plots:
    message:
        "IMO creating RMPM report"
    input:
        csv="{dir}.mh.blast.map/{ref}.csv",
        map="mapping.csv",
        rmd=srcdir("Genes.Rmd")
    output:
        "reports/{dir}.mh.blast.map__{ref}.pdf"
    run:
        from ymp.util import Rmd
        Rmd(rmd=input.rmd[0],
            out=output,
            csv=os.path.abspath(csv),
            map=os.path.abspath(map)
            )
        
